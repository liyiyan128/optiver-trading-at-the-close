{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import warnings\n",
    "from warnings import simplefilter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "\n",
    "IS_OFFLINE = False\n",
    "IS_INFER = True\n",
    "TRAINING = True\n",
    "MAX_LOOKBACK = np.nan\n",
    "SPLIT_DAY = 435"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/optiver-trading-at-the-close/train.csv\")\n",
    "df = df.dropna(subset=[\"target\"])\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df_shape = df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=0):\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            \n",
    "            if str(col_type)[:3] == \"int\":\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "               \n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "    if verbose:\n",
    "        logger.info(f\"Memory usage of dataframe is {start_mem:.2f} MB\")\n",
    "        end_mem = df.memory_usage().sum() / 1024**2\n",
    "        logger.info(f\"Memory usage after optimization is: {end_mem:.2f} MB\")\n",
    "        decrease = 100 * (start_mem - end_mem) / start_mem\n",
    "        logger.info(f\"Decreased by {decrease:.2f}%\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import njit, prange\n",
    "from itertools import combinations\n",
    "\n",
    "\n",
    "@njit(parallel=True)\n",
    "def compute_triplet_imbalance(df_values, comb_indices):\n",
    "    num_rows = df_values.shape[0]\n",
    "    num_combinations = len(comb_indices)\n",
    "    imbalance_features = np.empty((num_rows, num_combinations))\n",
    "    for i in prange(num_combinations):\n",
    "        a, b, c = comb_indices[i]\n",
    "        for j in range(num_rows):\n",
    "            max_val = max(df_values[j, a], df_values[j, b], df_values[j, c])\n",
    "            min_val = min(df_values[j, a], df_values[j, b], df_values[j, c])\n",
    "            mid_val = df_values[j, a] + df_values[j, b] + df_values[j, c] - min_val - max_val\n",
    "            \n",
    "            if mid_val == min_val:\n",
    "                imbalance_features[j, i] = np.nan\n",
    "            else:\n",
    "                imbalance_features[j, i] = (max_val - mid_val) / (mid_val - min_val)\n",
    "\n",
    "    return imbalance_features\n",
    "\n",
    "\n",
    "def calculate_triplet_imbalance_numba(price, df):\n",
    "    df_values = df[price].values\n",
    "    comb_indices = [(price.index(a), price.index(b), price.index(c)) for a, b, c in combinations(price, 3)]\n",
    "    features_array = compute_triplet_imbalance(df_values, comb_indices)\n",
    "    columns = [f\"imb3_{a}_{b}_{c}\" for a, b, c in combinations(price, 3)]\n",
    "    features = pd.DataFrame(features_array, columns=columns)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "def imbalance_features(df):\n",
    "\n",
    "    df[\"bid_ask_spread\"] = df[\"ask_price\"] - df[\"bid_price\"]\n",
    "    df[\"bid_ask_spread_diff\"] = df.groupby([\"stock_id\"])[\"bid_ask_spread\"].diff()  # change in bid ask spread by stock\n",
    "\n",
    "    df[\"volume\"] = df.eval(\"bid_size + ask_size\")\n",
    "    df[\"total_bid_value\"] = df.eval(\"bid_size * bid_price\")\n",
    "    df[\"total_ask_value\"] = df.eval(\"ask_size * ask_price\")\n",
    "\n",
    "    df[\"log_return\"] = df[\"wap\"].apply(lambda x: np.log(x) if x is not None else x)\n",
    "\n",
    "    df['imb_s1'] = df.eval(\"(bid_size - ask_size) / (bid_size + ask_size)\")  # liquidity imbalance\n",
    "    df['imb_s2'] = df.eval(\"(imbalance_size - matched_size) / (matched_size + imbalance_size)\")  # matched imbalance\n",
    "    df[\"imbalance_ratio\"] = df.eval(\"imbalance_size / matched_size\")\n",
    "\n",
    "    prices = [\"reference_price\", \"far_price\", \"near_price\", \"ask_price\", \"bid_price\", \"wap\"]\n",
    "    sizes = [\"imbalance_size\", \"bid_size\", \"ask_size\", \"matched_size\"]\n",
    "\n",
    "    for c in combinations(prices, 2):\n",
    "        df[f\"imb2_{c[0]}_{c[1]}\"] = df.eval(f\"({c[0]} - {c[1]}) / ({c[0]} + {c[1]})\")\n",
    "\n",
    "    for c in [prices, sizes]:\n",
    "        triplet_feature = calculate_triplet_imbalance_numba(c, df)\n",
    "        df[triplet_feature.columns] = triplet_feature.values\n",
    "\n",
    "    # Statistical aggregation features\n",
    "    for func in [\"mean\", \"std\", \"skew\", \"kurt\"]:\n",
    "        df[f\"prices_{func}\"] = df[prices].agg(func, axis=1)\n",
    "        df[f\"sizes_{func}\"] = df[sizes].agg(func, axis=1)\n",
    "\n",
    "    return df.replace([np.inf, -np.inf], 0)\n",
    "\n",
    "\n",
    "def other_features(df):\n",
    "    df[\"day_of_week\"] = df[\"date_id\"] % 5\n",
    "\n",
    "    pca = PCA(n_components=1)\n",
    "    prices = [\"reference_price\", \"far_price\", \"near_price\", \"ask_price\", \"bid_price\", \"wap\"]\n",
    "    df[\"pca_prices\"] = pca.fit_transform(df[prices].fillna(1))\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def feat_eng(df):\n",
    "    df = imbalance_features(df)\n",
    "    df = other_features(df)\n",
    "    gc.collect()  \n",
    "    features = [feat for feat in df.columns if feat not in [\"row_id\", \"time_id\", \"date_id\", \"target\"]]\n",
    "    return df[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IS_OFFLINE:\n",
    "    df_train = df[df[\"date_id\"] <= SPLIT_DAY]\n",
    "    df_valid = df[df[\"date_id\"] > SPLIT_DAY]\n",
    "    print(\"[OFFLINE]\")\n",
    "    print(f\"train: {df_train.shape}\\nvalid: {df_valid.shape}\")\n",
    "else:\n",
    "    df_train = df\n",
    "    print(\"[ONLINE]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAINING:\n",
    "    if IS_OFFLINE:\n",
    "        X_train = feat_eng(df_train)\n",
    "        print(\"Training set feature engeering finished.\")\n",
    "        X_valid = feat_eng(df_valid)\n",
    "        print(\"Valid set feature engeering finished.\")\n",
    "        X_valid = reduce_mem_usage(X_valid)\n",
    "    else:\n",
    "        X_train = feat_eng(df_train)\n",
    "        print(\"[ONLINE] Training set feature engeering finished.\")\n",
    "X_train = reduce_mem_usage(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import joblib  # for saving and loading models\n",
    "\n",
    "\n",
    "lgb_params = {\n",
    "    \"objective\": \"mae\",\n",
    "    \"n_estimators\": 6000,\n",
    "    \"num_leaves\": 256,\n",
    "    \"subsample\": 0.6,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"learning_rate\": 0.00871,\n",
    "    'max_depth': 11,\n",
    "    \"n_jobs\": 4,\n",
    "    \"device\": \"gpu\",\n",
    "    \"verbosity\": -1,\n",
    "    \"importance_type\": \"gain\",\n",
    "}\n",
    "\n",
    "features = X_train.columns.to_list()\n",
    "print(f\"Number of features: {len(features)}\")\n",
    "\n",
    "num_folds = 5\n",
    "fold_size = 480 // num_folds\n",
    "gap = 5\n",
    "\n",
    "models = []\n",
    "scores = []\n",
    "\n",
    "model_save_path = 'models' \n",
    "if not os.path.exists(model_save_path):\n",
    "    os.makedirs(model_save_path)\n",
    "\n",
    "date_ids = X_train['date_id'].values\n",
    "\n",
    "for i in range(num_folds):\n",
    "    start = i * fold_size\n",
    "    end = start + fold_size\n",
    "    if i < num_folds - 1:  # no need to purge after the last fold\n",
    "        purged_start = end - 2\n",
    "        purged_end = end + gap + 2\n",
    "        train_indices = (date_ids >= start) & (date_ids < purged_start) | (date_ids > purged_end)\n",
    "    else:\n",
    "        train_indices = (date_ids >= start) & (date_ids < end)\n",
    "    test_indices = (date_ids >= end) & (date_ids < end + fold_size)\n",
    "    \n",
    "    X_train_fold = X_train[train_indices]\n",
    "    y_train_fold = df_train['target'][train_indices]\n",
    "    X_valid_fold = X_train[test_indices]\n",
    "    y_valid_fold = df_train['target'][test_indices]\n",
    "\n",
    "    print(f\"Fold {i+1} LightGBM training\")\n",
    "    model = lgb.LGBMRegressor(**lgb_params)\n",
    "    model.fit(\n",
    "        X_train_fold[features],\n",
    "        y_train_fold,\n",
    "        eval_set=[(X_valid_fold[features], y_valid_fold)],\n",
    "        callbacks=[\n",
    "            lgb.callback.early_stopping(stopping_rounds=100),\n",
    "            lgb.callback.log_evaluation(period=100),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    models.append(model)\n",
    "    filename = os.path.join(model_save_path, f'fold_{i+1}.txt')\n",
    "    model.booster_.save_model(filename)\n",
    "    print(f\"Fold {i+1} model saved.\")\n",
    "\n",
    "    # Evaluate model performance on the validation set\n",
    "    y_pred = model.predict(X_valid_fold[features])\n",
    "    score = mean_absolute_error(y_pred, y_valid_fold)\n",
    "    scores.append(score)\n",
    "    print(f\"Fold {i+1} MAE: {score}\")\n",
    "\n",
    "    # Free up memory by deleting fold specific variables\n",
    "    del X_train_fold, y_train_fold, X_valid_fold, y_valid_fold\n",
    "    gc.collect()\n",
    "\n",
    "# Calculate the average best iteration from all folds\n",
    "average_best_iteration = int(np.mean([model.best_iteration_ for model in models]))\n",
    "\n",
    "# Update the lgb_params with the average best iteration\n",
    "lgb_params['n_estimators'] = average_best_iteration\n",
    "\n",
    "print(f\"Training final model with average best iteration: {average_best_iteration}\")\n",
    "\n",
    "# Train the final model on the entire dataset\n",
    "model = lgb.LGBMRegressor(**lgb_params)\n",
    "model.fit(\n",
    "    X_train[features],\n",
    "    df_train['target'],\n",
    "    callbacks=[\n",
    "        lgb.callback.log_evaluation(period=100),\n",
    "    ],\n",
    ")\n",
    "\n",
    "models.append(model)\n",
    "filename = os.path.join(model_save_path, 'lgbm.txt')\n",
    "model.booster_.save_model(filename)\n",
    "print(f\"Final LightGBM model saved.\")\n",
    "\n",
    "print(f\"Average MAE across all folds: {np.mean(scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature importance\n",
    "feat_imp = pd.Series(model.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
    "print(feat_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_sum(prices, volumes):\n",
    "    std_error = np.sqrt(volumes)\n",
    "    step = np.sum(prices) / np.sum(std_error)\n",
    "    out = prices - std_error * step\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IS_INFER:\n",
    "    import optiver2023\n",
    "    env = optiver2023.make_env()\n",
    "    iter_test = env.iter_test()\n",
    "    counter = 0\n",
    "\n",
    "    y_min, y_max = -64, 64\n",
    "    cache = pd.DataFrame()\n",
    "    model_weights = [1/len(models)] * len(models)\n",
    "    for (test, revealed_targets, sample_prediction) in iter_test:\n",
    "        cache = pd.concat([cache, test], ignore_index=True, axis=0)\n",
    "        if counter > 0:\n",
    "            cache = cache.groupby(['stock_id']).tail(21).sort_values(by=['date_id', 'seconds_in_bucket', 'stock_id']).reset_index(drop=True)\n",
    "        feature = feat_eng(cache)\n",
    "\n",
    "        lgb_predictions = np.zeros(len(test))\n",
    "        for model, weight in zip(models, model_weights):\n",
    "            lgb_predictions += weight * model.predict(feature)\n",
    "        lgb_predictions = zero_sum(lgb_predictions, test['bid_size'] + test['ask_size'])\n",
    "\n",
    "        clipped_predictions = np.clip(lgb_predictions, y_min, y_max)\n",
    "        sample_prediction['target'] = clipped_predictions\n",
    "        env.predict(sample_prediction)\n",
    "\n",
    "        counter += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
